{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python - Numpy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('./image.jpg')\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "result = np.zeros((image.shape[0], 256), dtype=np.uint8)\n",
    "\n",
    "hist = cv2.calcHist([image],[0],None,[256],[0,256])\n",
    "cv2.normalize(hist, hist, 0, 256, cv2.NORM_MINMAX)\n",
    "\n",
    "for x, y in enumerate(hist):\n",
    "    cv2.line(result, (x, image.shape[0]), (x, image.shape[0]-y), 255)\n",
    "    \n",
    "dst = np.hstack([image[:,:,0],result])\n",
    "cv2.imshow(\"dst\",dst)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4 5 6]\n",
      " [4 5 6]]\n",
      "[[[1.+0.j 2.+0.j 3.+0.j]]]\n",
      "[[1 2]\n",
      " [3 4]]\n"
     ]
    }
   ],
   "source": [
    "array1 = np.array([[1,2,3], [4,5,6]])\n",
    "array2 = np.array([1,2,3], dtype=complex, ndmin=3)\n",
    "\n",
    "array4 = np.array(np.mat('1 2; 3 4'), subok=True)\n",
    "\n",
    "array1[0] = [4,5,6]\n",
    "\n",
    "\n",
    "print(array1)\n",
    "print(array2)\n",
    "print(array4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 6  7  8  9 10]\n",
      " [11 12 13 14 15]]\n",
      "[[ 1  2  3  4  5]\n",
      " [11 12 13 14 15]]\n",
      "[12 14]\n"
     ]
    }
   ],
   "source": [
    "array = np.array([[1,2,3,4,5],\n",
    "                 [6,7,8,9,10],\n",
    "                 [11,12,13,14,15],\n",
    "                 [16,17,18,19,20]])\n",
    "\n",
    "print(array[1:3])\n",
    "print(array[::2])\n",
    "print(array[2, 1::2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0  1]\n",
      "  [ 2  3]\n",
      "  [ 4  5]]\n",
      "\n",
      " [[ 6  7]\n",
      "  [ 8  9]\n",
      "  [10 11]]]\n",
      "[[ 0  2  4  6  8 10]\n",
      " [ 1  3  5  7  9 11]]\n"
     ]
    }
   ],
   "source": [
    "array = np.arange(12)\n",
    "\n",
    "reshape1 = array.reshape(2,3,2)\n",
    "reshape2 = np.reshape(array, (2,-1), order='F')\n",
    "\n",
    "print(reshape1)\n",
    "print(reshape2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3]\n",
      "[[0 1 2 3]]\n",
      "[[0]\n",
      " [1]\n",
      " [2]\n",
      " [3]]\n",
      "[0 1 2 3]\n"
     ]
    }
   ],
   "source": [
    "array = np.arange(4)\n",
    "\n",
    "axis1 = array[np.newaxis]\n",
    "axis2 = array[:, np.newaxis]\n",
    "\n",
    "\n",
    "flat1 = axis2.flatten(order='F')\n",
    "print(array)\n",
    "print(axis1)\n",
    "print(axis2)\n",
    "print(flat1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0  1  2]\n",
      "  [ 3  4  5]]\n",
      "\n",
      " [[ 6  7  8]\n",
      "  [ 9 10 11]]]\n"
     ]
    }
   ],
   "source": [
    "array1 = np.arange(6).reshape(2,3)\n",
    "array2 = np.arange(6, 12).reshape(2,3)\n",
    "\n",
    "merge1 = np.stack([array1, array2], axis=0)\n",
    "merge2 = np.stack([array1, array2], axis=-1)\n",
    "\n",
    "print(merge1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0  6]\n",
      "  [ 1  7]\n",
      "  [ 2  8]]\n",
      "\n",
      " [[ 3  9]\n",
      "  [ 4 10]\n",
      "  [ 5 11]]]\n"
     ]
    }
   ],
   "source": [
    "print(merge2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 2 3 4]\n",
      " [5 6 7 8 9]]\n",
      "[array([[0, 1, 2, 3, 4]]), array([[5, 6, 7, 8, 9]])]\n",
      "[array([[0, 1],\n",
      "       [5, 6]]), array([[2],\n",
      "       [7]]), array([[3, 4],\n",
      "       [8, 9]])]\n"
     ]
    }
   ],
   "source": [
    "array = np.arange(10).reshape(2,5)\n",
    "\n",
    "detach1 = np.split(array, 2, axis=0)\n",
    "detach2 = np.split(array, [2,3], axis=1)\n",
    "\n",
    "print(array)\n",
    "print(detach1)\n",
    "print(detach2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2]\n",
      " [3 4]]\n",
      "[[2.5 4.5]\n",
      " [4.5 6.5]]\n"
     ]
    }
   ],
   "source": [
    "array1 = np.array([1,2,3,4]).reshape(2,2)\n",
    "array2 = np.array([1.5, 2.5])\n",
    "print(array1)\n",
    "\n",
    "add = array1 + array2\n",
    "print(add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1280, 1920, 3)\n",
      "(300, 300, 3)\n"
     ]
    }
   ],
   "source": [
    "array = np.zeros((1280, 1920, 3), np.uint8)\n",
    "x,y,w,h = 100, 100, 300, 300\n",
    "roi = array[x:x+w, y:y+h]\n",
    "\n",
    "print(array.shape)\n",
    "print(roi.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenCV Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 이미지 입력\n",
    "\n",
    "#### cv2.imread(이미지 경로, 플래그:이미지 입력 함수의 플래그)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 (863, 1300) uint8\n",
      "[[118  91 136 ... 237 237 237]\n",
      " [109 102 109 ... 238 238 238]\n",
      " [129 147 121 ... 238 238 238]\n",
      " ...\n",
      " [160 145 135 ...  51  47  40]\n",
      " [ 99 141 146 ...  46  44  37]\n",
      " [ 45 132 163 ...  44  45  42]]\n"
     ]
    }
   ],
   "source": [
    "src = cv2.imread(\"./image.jpg\", cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "print(src.ndim, src.shape, src.dtype)\n",
    "print(src)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 이미지 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.namedWindow(\"src\", flags = cv2.WINDOW_FREERATIO)\n",
    "cv2.resizeWindow(\"src\", 400, 200)\n",
    "cv2.imshow(\"src\",src)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyWindow(\"src\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "cv2.namedWindow(winname, flags=None): 화면에 이미지를 표시할 수 있는 윈도우를 생성.</p>\n",
    "cv2.resizeWindow(winname, width, height): winname과 동일한 윈도우의 크기를 설정.</p>\n",
    "cv2.imshow(winname, ndarray): 윈도우에 이미지를 표시.</p>\n",
    "cv2.waitKey(int delay): 지정된 시간 동안 키 입력이 있을 때까지 프로그램을 지연시킴.</p>\n",
    "cv2.destroyWindow(string winName): 윈도우를 제거.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 동영상 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "capture = cv2. VideoCapture(\"./count.mp4\")\n",
    "\n",
    "while True:\n",
    "    ret, frame = capture.read()\n",
    "    \n",
    "    if(capture.get(cv2.CAP_PROP_POS_FRAMES) == capture.get(cv2.CAP_PROP_FRAME_COUNT)):\n",
    "        capture.open('./count.mp4')\n",
    "        \n",
    "    cv2.imshow(\"VideoFrame\", frame)\n",
    "    if cv2.waitKey(33) == ord('q'): break  # 키보드에서 q를 누르면 동영상 출력이 종료됨.\n",
    "        \n",
    "capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "while문: 동영상에서 프레임을 모두 표시하기 위해 사용. </p>\n",
    "capture.read(): 동영상 파일에서 프레임을 가져와서 압축을 해제한 다음 bool과 ndarray 타입의 값을 반환.</p>\n",
    "- ret(bool)은 capture 변수에서 정상적으로 프레임을 읽었는지를 나타내고, frame(ndarray)은 현재 프레임을 나타낸다. </p>\n",
    "\n",
    "현재 프레임수(cv2.CAP_PROP_POS_FRAMES)가 동영상의 총 프레임 수(cv2.CAP_PROP_FRAME_COUNT)와 동일할 때 동영상 파일을 다시 읽어서 capture 변수에 동영상을 할당 or break문을 통해 반복문 종료. </p>\n",
    "\n",
    "cv2.imshow(): 이미지로 저장된 프레임을 윈도우에 표시.</p>\n",
    "- 이를 위해 cv2.waitKey()를 사용하여 33ms만큼 대기한 후, 다음 프레임으로 넘어가게 함.\n",
    "- Python OpenCV는 문자를 처리하지 못하므로, 유니코드 값으로 변환하기 위해 ord()를 활용. </p>\n",
    "\n",
    "capture.release(): 동영상 재생이 끝나면 동영상 파일을 닫고 메모리르 해제하기 위해 호출.</p>\n",
    "cv2.destroyAllWindows(): 모든 윈도우를 제거 (동영상 파일의 재생이 끝났기 때문에)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. 카메라 출력\n",
    "카메라가 스트리밍 형태로 동작할 때 사용. 즉, 데이터를 실시간으로 받아오고 분석해야 하는 경우 카메라를 이용해 데이터를 처리, </p>\n",
    "- Python OpenCVSharp의 카메라 출력 클래스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "captrue = cv2.VideoCapture(index)   #index: 카메라의 장치 번호."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "웹캡이 내장된 노트북이나 내장돼 있지 않은 컴퓨터에 카메라를 연결할 경우 장치 번호는 0. </p>\n",
    "카메라가 여러 대 연결돼 있다면 0이 아닌 1, 2, 3, ... 등의 장치 번호를 사용하여 외부 카메라 사용 가능."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "capture = cv2.VideoCapture(0)\n",
    "capture.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
    "capture.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "\n",
    "while True:\n",
    "    ret, frame = capture.read()\n",
    "    if ret == True:\n",
    "        cv2.imshow(\"VideoFrame\", frane)\n",
    "        if cv2.waitKey(33) == ord('q'): break\n",
    "            \n",
    "    else:\n",
    "        break\n",
    "        \n",
    "capture.release()\n",
    "cv2.destroyAllwindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. 도형 그리기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "영상이나 이미지 위에 그래픽을 그리는 것을 의미. OpenCv의 도형 그리기 함수는 주로 검출 결과를 시각적으로 표시하는 데 사용. 또한 이미지 위에 검출 결과를 새롭게 그려서 결과값을 변결하거나 보정하기 위해서도 사용."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 선형 타입: 도형을 그릴 때 어떤 유형의 선으로 그릴지 결정하는 인수. (브레젠험 알고리즘 방식(4-연결, 8-연결), 안티 엘리어싱 방식, 내부 채우기 방식이 존재)\n",
    "- 비트 시프트: 도형 그리기 함수에서 사용되는 일반적인 정수값 대신 비트 시프트를 활용하여 소수점 이하의 값이 포함된 실숫값 좌표로 도형 그리기 함수를 사용.\n",
    "- 직선 그리기: 이미지나 영상 위에 단순한 선을 그림. 주로 두 점을 이어서 검출된 결과를 사용자가 인식하기 쉽게 표시하거나 이미지의 특정 영역을 보정하기 위해 사용.\n",
    "- 사각형 그리기: 이미지나 영상 위에 단순한 사각형을 그림. 주로 관심 영역을 설정하기 위한 변숫값으로 활용하거나 검출된 결과를 사용자가 인식하기 쉽게 표시하는데 사용.\n",
    "- 원 그리기: 이미지나 영상 위에 단순한 원을 그림. 주로 검출된 좌표값을 사용자가 인식하기 쉽게 표시하는 데 사용함.\n",
    "- 호 그리기: 이미지나 영상 위에 단순한 호나 타원을 그림. 주로 검출된 타원을 그리거나 호를 그리거나 타원 객체의 부정확한 영역을 보정하기 위해 사용.\n",
    "- 내부가 채워지지 않은 다각형 그리기: 이미지나 영상 위에 여러 개의 다각형 곡선을 그림. 주로 복잡한 형상의 다각형을 그리거나 검출된 윤곽선의 일부를 시각적으로 확인할 때 사용됨.\n",
    "- 내부가 채워진 다각형 그리기: 이미지나 영상 위에 내부가 채워진 여러 개의 다각형 곡선을 그림. 주로 복잡한 형상의 다각형을 그리거나 결과를 이미지 위에 덮어 씌울 때 사용.\n",
    "- 문자 그리기: 이미지나 영상 위에 문자를 표시, 주로 검출된 결과에 시각적으로 라벨을 표시할 때 사용."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.zeros((768, 1366, 3), dtype=np.uint8)\n",
    "\n",
    "cv2.line(img, (100,100),(1200, 100), (0,0,255), 3, cv2.LINE_AA)\n",
    "cv2.circle(img, (300, 300), 50, (0,255,0), cv2.FILLED, cv2.LINE_4)\n",
    "cv2.rectangle(img, (500, 200), (1000, 400), (255,0,0), 5, cv2.LINE_8)\n",
    "cv2.ellipse(img, (1200, 300), (100, 50), 0, 90, 180, (255,255,0),2)\n",
    "\n",
    "pts1 = np.array([[[100,500], [300,500], [200,600]], [[400,500], [500,500], [600,700]]])\n",
    "pts2 = np.array([[700,500], [800,500], [700,600]])\n",
    "cv2.polylines(img, pts1, True, (0, 255,255),2)\n",
    "cv2.fillPoly(img, [pts2], (255,0,255), cv2.LINE_AA)\n",
    "\n",
    "cv2.putText(img, 'OpneCV', (900,600), cv2.FONT_HERSHEY_COMPLEX | cv2.FONT_ITALIC, 2, (255,255,255), 3)\n",
    "\n",
    "cv2.imshow('lmg', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. 결과 저장"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 이미지 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'img' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-bd3902f3a946>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msave\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./CV.jpeg'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIMWRITE_JPEG_QUALITY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIMWRITE_JPEG_PROGRESSIVE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'img' is not defined"
     ]
    }
   ],
   "source": [
    "save = cv2.imwrite('./CV.jpeg', img, (cv2.IMWRITE_JPEG_QUALITY, 100, cv2.IMWRITE_JPEG_PROGRESSIVE, 1))\n",
    "print(save)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 동영상 저장"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OpenCV에서는 동영상을 저장할 때 프레임의 변경이나 변형을 녹화해서 저장할 수 있다. 동영상 저장 함수는 이미지 저장 함수와 동일하게 파일명의 확장자와 설정된 코덱을 읽어 기록한다. 또한, 새롭게 파일을 생성함으로 함수를 호출할 때 사용할 코덱, 프레임 속도, 프레임 등을 입력해야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "capture = cv2.VideoCapture('./count.mp4')\n",
    "width = int(capture.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(capture.get(cv2.CAP_PROP_FRAME_HEIGHT)) \n",
    "# width, height를 선언해서 녹화할 동영상의 프레임 크기를 받아온다.\n",
    "# 프레임 크기는 float 형식으로 반환되므로, int 형식으로 변경함. (변경하지 않을 경우, 동영상 저장 함수에서 오류가 발생함.)\n",
    "\n",
    "videoWriter = cv2.VideoWriter()\n",
    "# cv2.VideoWriter()를 통해 녹화를 위한 메모리 할당.\n",
    "\n",
    "isWrite = False\n",
    "# isWrite는 특정 프레임만 녹화하기 위해 구분하는 bool 형식 변수.\n",
    "\n",
    "\n",
    "while True:\n",
    "# isWrite가 True일 때만 녹화를 시작함.\n",
    "    ret, frame = capture.read()\n",
    "    \n",
    "    if(capture.get(cv2.CAP_PROP_POS_FRAMES) == capture.get(cv2.CAP_PROP_FRAME_COUNT)):\n",
    "        capture.open('./count.mp4')\n",
    "        \n",
    "    cv2.imshow('VideoFrame', frame)\n",
    "    key = cv2.waitKey(33)\n",
    "    \n",
    "    \n",
    "    if key == 4:  # Alt + D 의미. 해당 키가 입력 되어있을때, 녹화를 시작함.\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'XVID') # cv2.VideoWriter_fourcc(*'XVID')를 활용하여 코덱을 설정.\n",
    "        \n",
    "        videoWriter.open('./Video.avi', fourcc, 30, (width, height), True)\n",
    "        isWrite = True\n",
    "        \n",
    "    elif key == 24:  # Alt + X 의미, 해당 키가 입력되었을때, 녹화를 종료함.\n",
    "        videoWriter.release()  # 메모리 할당을 해제하고 녹화 함수를 종료함.\n",
    "        isWrite = False\n",
    "        \n",
    "    elif key == ord('q'): break\n",
    "        \n",
    "    if isWrite == True:\n",
    "        videoWriter.write(frame)\n",
    "        \n",
    "videoWriter.release()\n",
    "capture.release()\n",
    "cv2.destroyAllWindows()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 이미지 변형\n",
    "## 1. 색상 공간 변환"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "본래의 색상 공간에서 다른 생삭 공간으로 변환활 때 사용. 색상 공간 변환 함수는 데이터 타입을 같게 유지하고 채널을 변환함. </p>\n",
    "색상 공간 변환 함수: 입력 이미지(src)에 색상 변환 코드를 적용해서 출력 이미지(dst)로 변환. (색상 변환 코드를 사용해서 BGR 색상 공간을 RGBA 색상 공간으로 변환하거나 그레이스케일, HSV, CIE, Luv 등 단일 채널부터 3채널, 4채널의 색상 공간으로도 변환이 가능."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = cv2.imread('./image.jpg')\n",
    "dst = cv2.cvtColor(src, cv2.COLOR_BGR2HSV)  # 다중 채널 색상 이미지(HSV)로 변환\n",
    "\n",
    "cv2.imshow('dst',dst)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. HSV 색상 공간\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "색상을 표현하기에 가장 간편한 색상 공간. 이미지에서 색상을 검출한다고 가정할 때, BGR이나, RGB 패턴으로는 인간이 인지하는 영역의 색상을 구별하기에는 매우 어렵고 복잡하지만, HSV 색상 공간을 활용하면 간편하고 빠르게 특정 색상을 검출하고 분리할 수 있음."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "색상을 검출하려면 각 매개변수에 색상의 범위를 상수 값으로 할당해야함. 그러므로 각 속성이 어떤 역할을 하는지, 어떤 범위를 갖는지 등을 충분히 이해해야함. </p>\n",
    "- 색상(Hue): 세 속성 중 하나로, 색깔의 질을 의미. 빨간, 노랑, 파랑 등의 표현으로 나타내는 성질.\n",
    "- 채도(Saturation): 색의 선명도를 의미하며, 아무것도 섞지 않아 맑고 깨끗하며 원색에 가까운 것을 채도가 높다고 표현.\n",
    "- 명도(Value): 색의 밝기. 명도가 높을수록 백색에, 낮을수록 흑색에 가까워짐.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "만약 이미지에서 빨간색 색상을 검출한다면 원형 색상의 범위로 인해 최솟값과 최댓값의 범위를 지정하는 데 어려움을 겪는다. 단순히 최솟값을 약 170, 최댓값을 약 10으로 설정해서 검출을 진행할 경우 오류가 발생한다. 이를 해결하기 위해 두 번에 걸쳐 색상 채널을 나누고 합치는 연산을 해야한다.</p>\n",
    "- 빨간색 계열을 나눠서 낮은 쪽의 빨간색 채널, 높은 쪽의 빨간색 채널을 만든 후 채녈을 합산함. 이를 위해 먼저 색상 공간을 채널별로 나눠야함.\n",
    "\n",
    "\n",
    "#### 채널 분리 함수: cv2.split()\n",
    "\n",
    "채널 분리 함수는 다중 입력 이미지(src)를 단일 채널 이미지 배열(mv)로 나눈다. 3채널 이미지를 분리할 경우 단일 채널 이미지로 나눠져 세 개의 결과 이미지로 생성된다. mv 배열 안에는 첫 번째 채널 (mv[0]), 두 번째 채널(mv[1]), 세 번째 채널(mv[2])이 포함돼 있다. Python OpenCV에서는 리스트 형태로 반환됨.</p>\n",
    "\n",
    "\n",
    "#### 채널 병합 함수: cv2.merge()\n",
    "\n",
    "채널 병합 함수는 단일 채널 이미지 배열(mv)를 병합해 하나의 출력 이미지(dst)로 반환한다. 채널 분리 함수와 밴대로 작동하며, mv 배열 안에는 첫 번째 채널(mv[0]), 두 번째 채널(mv[1]), 세 번째 채널(mv[2])이 포함돼야 한다. 또한 mv 배열의 첫 번째 채널이 채널 별하의 기준이 되어 모든 채널의 속성이 첫 번째 채널의 속성과 일치해야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
