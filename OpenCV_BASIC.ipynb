{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python - Numpy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('./image.jpg')\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "result = np.zeros((image.shape[0], 256), dtype=np.uint8)\n",
    "\n",
    "hist = cv2.calcHist([image],[0],None,[256],[0,256])\n",
    "cv2.normalize(hist, hist, 0, 256, cv2.NORM_MINMAX)\n",
    "\n",
    "for x, y in enumerate(hist):\n",
    "    cv2.line(result, (x, image.shape[0]), (x, image.shape[0]-y), 255)\n",
    "    \n",
    "dst = np.hstack([image[:,:,0],result])\n",
    "cv2.imshow(\"dst\",dst)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4 5 6]\n",
      " [4 5 6]]\n",
      "[[[1.+0.j 2.+0.j 3.+0.j]]]\n",
      "[[1 2]\n",
      " [3 4]]\n"
     ]
    }
   ],
   "source": [
    "array1 = np.array([[1,2,3], [4,5,6]])\n",
    "array2 = np.array([1,2,3], dtype=complex, ndmin=3)\n",
    "\n",
    "array4 = np.array(np.mat('1 2; 3 4'), subok=True)\n",
    "\n",
    "array1[0] = [4,5,6]\n",
    "\n",
    "\n",
    "print(array1)\n",
    "print(array2)\n",
    "print(array4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 6  7  8  9 10]\n",
      " [11 12 13 14 15]]\n",
      "[[ 1  2  3  4  5]\n",
      " [11 12 13 14 15]]\n",
      "[12 14]\n"
     ]
    }
   ],
   "source": [
    "array = np.array([[1,2,3,4,5],\n",
    "                 [6,7,8,9,10],\n",
    "                 [11,12,13,14,15],\n",
    "                 [16,17,18,19,20]])\n",
    "\n",
    "print(array[1:3])\n",
    "print(array[::2])\n",
    "print(array[2, 1::2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0  1]\n",
      "  [ 2  3]\n",
      "  [ 4  5]]\n",
      "\n",
      " [[ 6  7]\n",
      "  [ 8  9]\n",
      "  [10 11]]]\n",
      "[[ 0  2  4  6  8 10]\n",
      " [ 1  3  5  7  9 11]]\n"
     ]
    }
   ],
   "source": [
    "array = np.arange(12)\n",
    "\n",
    "reshape1 = array.reshape(2,3,2)\n",
    "reshape2 = np.reshape(array, (2,-1), order='F')\n",
    "\n",
    "print(reshape1)\n",
    "print(reshape2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3]\n",
      "[[0 1 2 3]]\n",
      "[[0]\n",
      " [1]\n",
      " [2]\n",
      " [3]]\n",
      "[0 1 2 3]\n"
     ]
    }
   ],
   "source": [
    "array = np.arange(4)\n",
    "\n",
    "axis1 = array[np.newaxis]\n",
    "axis2 = array[:, np.newaxis]\n",
    "\n",
    "\n",
    "flat1 = axis2.flatten(order='F')\n",
    "print(array)\n",
    "print(axis1)\n",
    "print(axis2)\n",
    "print(flat1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0  1  2]\n",
      "  [ 3  4  5]]\n",
      "\n",
      " [[ 6  7  8]\n",
      "  [ 9 10 11]]]\n"
     ]
    }
   ],
   "source": [
    "array1 = np.arange(6).reshape(2,3)\n",
    "array2 = np.arange(6, 12).reshape(2,3)\n",
    "\n",
    "merge1 = np.stack([array1, array2], axis=0)\n",
    "merge2 = np.stack([array1, array2], axis=-1)\n",
    "\n",
    "print(merge1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0  6]\n",
      "  [ 1  7]\n",
      "  [ 2  8]]\n",
      "\n",
      " [[ 3  9]\n",
      "  [ 4 10]\n",
      "  [ 5 11]]]\n"
     ]
    }
   ],
   "source": [
    "print(merge2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 2 3 4]\n",
      " [5 6 7 8 9]]\n",
      "[array([[0, 1, 2, 3, 4]]), array([[5, 6, 7, 8, 9]])]\n",
      "[array([[0, 1],\n",
      "       [5, 6]]), array([[2],\n",
      "       [7]]), array([[3, 4],\n",
      "       [8, 9]])]\n"
     ]
    }
   ],
   "source": [
    "array = np.arange(10).reshape(2,5)\n",
    "\n",
    "detach1 = np.split(array, 2, axis=0)\n",
    "detach2 = np.split(array, [2,3], axis=1)\n",
    "\n",
    "print(array)\n",
    "print(detach1)\n",
    "print(detach2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2]\n",
      " [3 4]]\n",
      "[[2.5 4.5]\n",
      " [4.5 6.5]]\n"
     ]
    }
   ],
   "source": [
    "array1 = np.array([1,2,3,4]).reshape(2,2)\n",
    "array2 = np.array([1.5, 2.5])\n",
    "print(array1)\n",
    "\n",
    "add = array1 + array2\n",
    "print(add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1280, 1920, 3)\n",
      "(300, 300, 3)\n"
     ]
    }
   ],
   "source": [
    "array = np.zeros((1280, 1920, 3), np.uint8)\n",
    "x,y,w,h = 100, 100, 300, 300\n",
    "roi = array[x:x+w, y:y+h]\n",
    "\n",
    "print(array.shape)\n",
    "print(roi.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenCV Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 이미지 입력\n",
    "\n",
    "#### cv2.imread(이미지 경로, 플래그:이미지 입력 함수의 플래그)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 (863, 1300) uint8\n",
      "[[118  91 136 ... 237 237 237]\n",
      " [109 102 109 ... 238 238 238]\n",
      " [129 147 121 ... 238 238 238]\n",
      " ...\n",
      " [160 145 135 ...  51  47  40]\n",
      " [ 99 141 146 ...  46  44  37]\n",
      " [ 45 132 163 ...  44  45  42]]\n"
     ]
    }
   ],
   "source": [
    "src = cv2.imread(\"./image.jpg\", cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "print(src.ndim, src.shape, src.dtype)\n",
    "print(src)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 이미지 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.namedWindow(\"src\", flags = cv2.WINDOW_FREERATIO)\n",
    "cv2.resizeWindow(\"src\", 400, 200)\n",
    "cv2.imshow(\"src\",src)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyWindow(\"src\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "cv2.namedWindow(winname, flags=None): 화면에 이미지를 표시할 수 있는 윈도우를 생성.</p>\n",
    "cv2.resizeWindow(winname, width, height): winname과 동일한 윈도우의 크기를 설정.</p>\n",
    "cv2.imshow(winname, ndarray): 윈도우에 이미지를 표시.</p>\n",
    "cv2.waitKey(int delay): 지정된 시간 동안 키 입력이 있을 때까지 프로그램을 지연시킴.</p>\n",
    "cv2.destroyWindow(string winName): 윈도우를 제거.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 동영상 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "capture = cv2. VideoCapture(\"./count.mp4\")\n",
    "\n",
    "while True:\n",
    "    ret, frame = capture.read()\n",
    "    \n",
    "    if(capture.get(cv2.CAP_PROP_POS_FRAMES) == capture.get(cv2.CAP_PROP_FRAME_COUNT)):\n",
    "        capture.open('./count.mp4')\n",
    "        \n",
    "    cv2.imshow(\"VideoFrame\", frame)\n",
    "    if cv2.waitKey(33) == ord('q'): break  # 키보드에서 q를 누르면 동영상 출력이 종료됨.\n",
    "        \n",
    "capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "while문: 동영상에서 프레임을 모두 표시하기 위해 사용. </p>\n",
    "capture.read(): 동영상 파일에서 프레임을 가져와서 압축을 해제한 다음 bool과 ndarray 타입의 값을 반환.</p>\n",
    "- ret(bool)은 capture 변수에서 정상적으로 프레임을 읽었는지를 나타내고, frame(ndarray)은 현재 프레임을 나타낸다. </p>\n",
    "\n",
    "현재 프레임수(cv2.CAP_PROP_POS_FRAMES)가 동영상의 총 프레임 수(cv2.CAP_PROP_FRAME_COUNT)와 동일할 때 동영상 파일을 다시 읽어서 capture 변수에 동영상을 할당 or break문을 통해 반복문 종료. </p>\n",
    "\n",
    "cv2.imshow(): 이미지로 저장된 프레임을 윈도우에 표시.</p>\n",
    "- 이를 위해 cv2.waitKey()를 사용하여 33ms만큼 대기한 후, 다음 프레임으로 넘어가게 함.\n",
    "- Python OpenCV는 문자를 처리하지 못하므로, 유니코드 값으로 변환하기 위해 ord()를 활용. </p>\n",
    "\n",
    "capture.release(): 동영상 재생이 끝나면 동영상 파일을 닫고 메모리르 해제하기 위해 호출.</p>\n",
    "cv2.destroyAllWindows(): 모든 윈도우를 제거 (동영상 파일의 재생이 끝났기 때문에)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. 카메라 출력\n",
    "카메라가 스트리밍 형태로 동작할 때 사용. 즉, 데이터를 실시간으로 받아오고 분석해야 하는 경우 카메라를 이용해 데이터를 처리, </p>\n",
    "- Python OpenCVSharp의 카메라 출력 클래스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "captrue = cv2.VideoCapture(index)   #index: 카메라의 장치 번호."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "웹캡이 내장된 노트북이나 내장돼 있지 않은 컴퓨터에 카메라를 연결할 경우 장치 번호는 0. </p>\n",
    "카메라가 여러 대 연결돼 있다면 0이 아닌 1, 2, 3, ... 등의 장치 번호를 사용하여 외부 카메라 사용 가능."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "capture = cv2.VideoCapture(0)\n",
    "capture.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
    "capture.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "\n",
    "while True:\n",
    "    ret, frame = capture.read()\n",
    "    if ret == True:\n",
    "        cv2.imshow(\"VideoFrame\", frane)\n",
    "        if cv2.waitKey(33) == ord('q'): break\n",
    "            \n",
    "    else:\n",
    "        break\n",
    "        \n",
    "capture.release()\n",
    "cv2.destroyAllwindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. 도형 그리기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "영상이나 이미지 위에 그래픽을 그리는 것을 의미. OpenCv의 도형 그리기 함수는 주로 검출 결과를 시각적으로 표시하는 데 사용. 또한 이미지 위에 검출 결과를 새롭게 그려서 결과값을 변결하거나 보정하기 위해서도 사용."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 선형 타입: 도형을 그릴 때 어떤 유형의 선으로 그릴지 결정하는 인수. (브레젠험 알고리즘 방식(4-연결, 8-연결), 안티 엘리어싱 방식, 내부 채우기 방식이 존재)\n",
    "- 비트 시프트: 도형 그리기 함수에서 사용되는 일반적인 정수값 대신 비트 시프트를 활용하여 소수점 이하의 값이 포함된 실숫값 좌표로 도형 그리기 함수를 사용.\n",
    "- 직선 그리기: 이미지나 영상 위에 단순한 선을 그림. 주로 두 점을 이어서 검출된 결과를 사용자가 인식하기 쉽게 표시하거나 이미지의 특정 영역을 보정하기 위해 사용.\n",
    "- 사각형 그리기: 이미지나 영상 위에 단순한 사각형을 그림. 주로 관심 영역을 설정하기 위한 변숫값으로 활용하거나 검출된 결과를 사용자가 인식하기 쉽게 표시하는데 사용.\n",
    "- 원 그리기: 이미지나 영상 위에 단순한 원을 그림. 주로 검출된 좌표값을 사용자가 인식하기 쉽게 표시하는 데 사용함.\n",
    "- 호 그리기: 이미지나 영상 위에 단순한 호나 타원을 그림. 주로 검출된 타원을 그리거나 호를 그리거나 타원 객체의 부정확한 영역을 보정하기 위해 사용.\n",
    "- 내부가 채워지지 않은 다각형 그리기: 이미지나 영상 위에 여러 개의 다각형 곡선을 그림. 주로 복잡한 형상의 다각형을 그리거나 검출된 윤곽선의 일부를 시각적으로 확인할 때 사용됨.\n",
    "- 내부가 채워진 다각형 그리기: 이미지나 영상 위에 내부가 채워진 여러 개의 다각형 곡선을 그림. 주로 복잡한 형상의 다각형을 그리거나 결과를 이미지 위에 덮어 씌울 때 사용.\n",
    "- 문자 그리기: 이미지나 영상 위에 문자를 표시, 주로 검출된 결과에 시각적으로 라벨을 표시할 때 사용."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.zeros((768, 1366, 3), dtype=np.uint8)\n",
    "\n",
    "cv2.line(img, (100,100),(1200, 100), (0,0,255), 3, cv2.LINE_AA)\n",
    "cv2.circle(img, (300, 300), 50, (0,255,0), cv2.FILLED, cv2.LINE_4)\n",
    "cv2.rectangle(img, (500, 200), (1000, 400), (255,0,0), 5, cv2.LINE_8)\n",
    "cv2.ellipse(img, (1200, 300), (100, 50), 0, 90, 180, (255,255,0),2)\n",
    "\n",
    "pts1 = np.array([[[100,500], [300,500], [200,600]], [[400,500], [500,500], [600,700]]])\n",
    "pts2 = np.array([[700,500], [800,500], [700,600]])\n",
    "cv2.polylines(img, pts1, True, (0, 255,255),2)\n",
    "cv2.fillPoly(img, [pts2], (255,0,255), cv2.LINE_AA)\n",
    "\n",
    "cv2.putText(img, 'OpneCV', (900,600), cv2.FONT_HERSHEY_COMPLEX | cv2.FONT_ITALIC, 2, (255,255,255), 3)\n",
    "\n",
    "cv2.imshow('lmg', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. 결과 저장"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 이미지 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'img' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-bd3902f3a946>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msave\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./CV.jpeg'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIMWRITE_JPEG_QUALITY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIMWRITE_JPEG_PROGRESSIVE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'img' is not defined"
     ]
    }
   ],
   "source": [
    "save = cv2.imwrite('./CV.jpeg', img, (cv2.IMWRITE_JPEG_QUALITY, 100, cv2.IMWRITE_JPEG_PROGRESSIVE, 1))\n",
    "print(save)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 동영상 저장"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OpenCV에서는 동영상을 저장할 때 프레임의 변경이나 변형을 녹화해서 저장할 수 있다. 동영상 저장 함수는 이미지 저장 함수와 동일하게 파일명의 확장자와 설정된 코덱을 읽어 기록한다. 또한, 새롭게 파일을 생성함으로 함수를 호출할 때 사용할 코덱, 프레임 속도, 프레임 등을 입력해야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "capture = cv2.VideoCapture('./count.mp4')\n",
    "width = int(capture.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(capture.get(cv2.CAP_PROP_FRAME_HEIGHT)) \n",
    "# width, height를 선언해서 녹화할 동영상의 프레임 크기를 받아온다.\n",
    "# 프레임 크기는 float 형식으로 반환되므로, int 형식으로 변경함. (변경하지 않을 경우, 동영상 저장 함수에서 오류가 발생함.)\n",
    "\n",
    "videoWriter = cv2.VideoWriter()\n",
    "# cv2.VideoWriter()를 통해 녹화를 위한 메모리 할당.\n",
    "\n",
    "isWrite = False\n",
    "# isWrite는 특정 프레임만 녹화하기 위해 구분하는 bool 형식 변수.\n",
    "\n",
    "\n",
    "while True:\n",
    "# isWrite가 True일 때만 녹화를 시작함.\n",
    "    ret, frame = capture.read()\n",
    "    \n",
    "    if(capture.get(cv2.CAP_PROP_POS_FRAMES) == capture.get(cv2.CAP_PROP_FRAME_COUNT)):\n",
    "        capture.open('./count.mp4')\n",
    "        \n",
    "    cv2.imshow('VideoFrame', frame)\n",
    "    key = cv2.waitKey(33)\n",
    "    \n",
    "    \n",
    "    if key == 4:  # Alt + D 의미. 해당 키가 입력 되어있을때, 녹화를 시작함.\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'XVID') # cv2.VideoWriter_fourcc(*'XVID')를 활용하여 코덱을 설정.\n",
    "        \n",
    "        videoWriter.open('./Video.avi', fourcc, 30, (width, height), True)\n",
    "        isWrite = True\n",
    "        \n",
    "    elif key == 24:  # Alt + X 의미, 해당 키가 입력되었을때, 녹화를 종료함.\n",
    "        videoWriter.release()  # 메모리 할당을 해제하고 녹화 함수를 종료함.\n",
    "        isWrite = False\n",
    "        \n",
    "    elif key == ord('q'): break\n",
    "        \n",
    "    if isWrite == True:\n",
    "        videoWriter.write(frame)\n",
    "        \n",
    "videoWriter.release()\n",
    "capture.release()\n",
    "cv2.destroyAllWindows()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 이미지 변형\n",
    "## 1. 색상 공간 변환"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "본래의 색상 공간에서 다른 생삭 공간으로 변환활 때 사용. 색상 공간 변환 함수는 데이터 타입을 같게 유지하고 채널을 변환함. </p>\n",
    "색상 공간 변환 함수: 입력 이미지(src)에 색상 변환 코드를 적용해서 출력 이미지(dst)로 변환. (색상 변환 코드를 사용해서 BGR 색상 공간을 RGBA 색상 공간으로 변환하거나 그레이스케일, HSV, CIE, Luv 등 단일 채널부터 3채널, 4채널의 색상 공간으로도 변환이 가능."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = cv2.imread('./image.jpg')\n",
    "dst = cv2.cvtColor(src, cv2.COLOR_BGR2HSV)  # 다중 채널 색상 이미지(HSV)로 변환\n",
    "\n",
    "cv2.imshow('dst',dst)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. HSV 색상 공간\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "색상을 표현하기에 가장 간편한 색상 공간. 이미지에서 색상을 검출한다고 가정할 때, BGR이나, RGB 패턴으로는 인간이 인지하는 영역의 색상을 구별하기에는 매우 어렵고 복잡하지만, HSV 색상 공간을 활용하면 간편하고 빠르게 특정 색상을 검출하고 분리할 수 있음."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "색상을 검출하려면 각 매개변수에 색상의 범위를 상수 값으로 할당해야함. 그러므로 각 속성이 어떤 역할을 하는지, 어떤 범위를 갖는지 등을 충분히 이해해야함. </p>\n",
    "- 색상(Hue): 세 속성 중 하나로, 색깔의 질을 의미. 빨간, 노랑, 파랑 등의 표현으로 나타내는 성질.\n",
    "- 채도(Saturation): 색의 선명도를 의미하며, 아무것도 섞지 않아 맑고 깨끗하며 원색에 가까운 것을 채도가 높다고 표현.\n",
    "- 명도(Value): 색의 밝기. 명도가 높을수록 백색에, 낮을수록 흑색에 가까워짐.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "만약 이미지에서 빨간색 색상을 검출한다면 원형 색상의 범위로 인해 최솟값과 최댓값의 범위를 지정하는 데 어려움을 겪는다. 단순히 최솟값을 약 170, 최댓값을 약 10으로 설정해서 검출을 진행할 경우 오류가 발생한다. 이를 해결하기 위해 두 번에 걸쳐 색상 채널을 나누고 합치는 연산을 해야한다.</p>\n",
    "- 빨간색 계열을 나눠서 낮은 쪽의 빨간색 채널, 높은 쪽의 빨간색 채널을 만든 후 채녈을 합산함. 이를 위해 먼저 색상 공간을 채널별로 나눠야함.\n",
    "\n",
    "\n",
    "### 채널 분리 함수: cv2.split()\n",
    "\n",
    "채널 분리 함수는 다중 입력 이미지(src)를 단일 채널 이미지 배열(mv)로 나눈다. 3채널 이미지를 분리할 경우 단일 채널 이미지로 나눠져 세 개의 결과 이미지로 생성된다. mv 배열 안에는 첫 번째 채널 (mv[0]), 두 번째 채널(mv[1]), 세 번째 채널(mv[2])이 포함돼 있다. Python OpenCV에서는 리스트 형태로 반환됨.</p>\n",
    "\n",
    "### 채널 병합 함수: cv2.merge()\n",
    "\n",
    "채널 병합 함수는 단일 채널 이미지 배열(mv)를 병합해 하나의 출력 이미지(dst)로 반환한다. 채널 분리 함수와 반대로 작동하며, mv 배열 안에는 첫 번째 채널(mv[0]), 두 번째 채널(mv[1]), 세 번째 채널(mv[2])이 포함돼야 한다. 또한 mv 배열의 첫 번째 채널이 채널 별하의 기준이 되어 모든 채널의 속성이 첫 번째 채널의 속성과 일치해야 한다.\n",
    "\n",
    "\n",
    "### 배열 요소의 범위 설정 함수: cv2.InRange()\n",
    "\n",
    "다중 채널 이미지에서 단일 채널을 갖는 이미지들로 분리했다면 해당 채널에서 특정 범위의 값으로 검출해야함. 검출하려는 값과 일치하는 범위는 255를 할당하고 검출하려는 값과 일치하지 않는 범위는 0의 값을 할당한다. 이때 배열 요소의 범위 설정 함수를 사용.</p>\n",
    "\n",
    "배열 요소 범위 설정 함수는 입력 이미지(src)에서 낮은 범위(lowerb)에서 높은 범위(upperb) 사이의 요소를 검출한다. 범위 안에 포함되는 값을 255로 변경하며, 포함되지 않는 값은 0으로 변경해서 출력 이미지(dst)로 반환한다.</p>\n",
    "\n",
    "Python OpenCV에서는 튜플 자료형을 사용해 범위를 할당함. 단일 채널 이미지의 경우 int 형식으로 v값을 할당해서 사용하며, 다중 채널 이미지의 경우 (v0, v1, v2)형식으로 할당한다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = cv2.imread('./image.jpg')\n",
    "hsv = cv2.cvtColor(src, cv2.COLOR_BGR2HSV)  #원본 이미지를 HSV 색상 공간 이미지로 변환.\n",
    "\n",
    "h, s, v = cv2.split(hsv)  # HSV 색상 공간(배열 이미지)에 채널을 분리하여 할당.\n",
    "h_red = cv2.inRange(h,0,5)  # Hue채널에 범위를 할당한 후 빨간색 색상 범위를 갖는 객체만 검출.\n",
    "\n",
    "dst = cv2.bitwise_and(hsv, hsv, mask=h_red)  \n",
    "# h_red 이미지는 Hue 채널에서 0~5 사이의 값을 지니는 요서만 255 값으로 변경하고 나머지는 모두 0으로 변경한다.\n",
    "# 특정 요소가 검출이 완료되면 HSV 이미지 위에 마스크를 씌워 검출된 요소만 보이게 한다.\n",
    "\n",
    "dst = cv2.cvtColor(dst, cv2.COLOR_HSV2BGR)\n",
    "# cv2.imshow()함수는 BGR색상 공간만 정상적으로 출력하므로, HSV 색상 공간을 다시 BGR 색상 공간으로 변경한다.\n",
    "\n",
    "cv2.imshow('dst', dst)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "비교적 우수하게 검풀에 성공했지만 부정확한 요소를 검출하거나 거의 완벽하게 검출에 성공하지는 못했다. 단순히 HSV 공간 중 Hue의 공간만 활용해 검출했지 때문이다. 도한 붉은색은 앞선 Hue 공간의 범위에서 알 수 잇듯이, 170 이상의 값도 붉은 색에 포함된다. </p>\n",
    "이 문제를 해결하려면 배열 요소의 범위 설정 함수를 HSV 색상 공간으로 범위를 설정하고 검출한 두 요소의 배열을 병합해서 하나의 공간으로 만들어야 한다.</p>\n",
    "\n",
    "\n",
    "### 배열 병합 함수: cv2.addWeighted()\n",
    "\n",
    "배열 병합 함수는 입력 이미지1(src1)에 대한 가중치(alpha) 곱과 입력 이미지2(src2)에 대한 가중치(beta) 곱의 합 중 추가 합(gamma)를 더해서 계산한다. 선택 깊이(dtype)는 정밀도를 임의로 설정할 수 있다. 기본값을 사용할 경우 입력 이미지1(src1)의 정밀도로 설정된다.</p>\n",
    "\n",
    "- 배열 병합 함수 수식: dst = (src1 * alpha) + (src2 * beta) + gamma\n",
    "\n",
    "배열 병합 함수는 알파 블렌딩(alpha blending)을 구현할 수 있어서 서로 다른 이미지를 불투명하게 혼합해서 표시할 수 있다.</p>\n",
    "입력 이미지1과 입력 이미지2를 어떠한 변화 없이 사용할 경우, alpha값은 1.0, beta값은 0.0으로 할당해서 사용한다. 출력 이미지는 두 입력 이미지의 정밀도가 같으므로 기본값을 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = cv2.imread('./image.jpg')\n",
    "hsv = cv2.cvtColor(src, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "h, s, v = cv2.split(hsv)\n",
    "\n",
    "orange = cv2.inRange(hsv, (8, 100, 100), (20, 255, 255))\n",
    "blue = cv2.inRange(hsv, (110, 100, 100), (130, 255, 255))\n",
    "mix_color = cv2.addWeighted(orange, 10., blue, 1.0, 0,0)   \n",
    "# 배열 병합 함수를 활용해 orangr와 blue의 배열을 병합해 mix_color의 배열로 출력한다.\n",
    "# 함수에서 가중치의 할당 없이 병합하므로, alpha는 1.0, beta는 0.0의 값을 사용한다.\n",
    "\n",
    "dst = cv2.bitwise_and(hsv, hsv, mask =mix_color)\n",
    "dst = cv2.cvtColor(dst, cv2.COLOR_HSV2BGR)\n",
    "\n",
    "cv2.imshow('dst', dst)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# 출력 결과에서 주황색 객체와 파란색 객체 두 가지 색상이 반환된 것을 확인할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 이진화\n",
    "동영상이나  이미지에서 어느 지점을 기준으로 픽셀을 분류해서 제외해야 할 때가 있다. 이때 특정 값을 기준으로 값이 높거나 낮은 픽셀을 검은색 또는 흰색의 값으로 변경한다. 즉, 기준값에 따라 이분법적으로 구분해서 픽셀을 참 또는 거짓으로 나누는 연산이며, 이미지 행렬에서 모든 픽셀에 대해 이러한 연산을 수행하는 것이 이진화. </p>\n",
    "\n",
    "\n",
    "### 이진화 함수: cv2.threshold()\n",
    "이진화 함수는 입력 이미지(src)를 임곗값 형식(type)에 따라 특정한 비교 연산을 진행한다. 임곗값(thresh)보다 낮은 픽셀값은 0이나 원본 필셀값으로 변경하며, 임곗값(thresh)보다 높은 픽셀값은 최댓값(maxval)으로 변경한다. 변형된 이미지는 출력 이미지(dst)에 저장되며, Python OpenCV에서는 설정 임곗값(retval)도 반환된다.</p>\n",
    "\n",
    "일반적으로 이진화 함수는 단일 채널 이미지에서 활용되며, 다중 채널 이미지에 이진화 함수를 적용할 경우 각 채널을 분리해서 이진화 함수를 적용한 후 이미지를 다시 병합해서 반환한다. 특정 임곗값 형식에서는 단일 채널 이미지만을 지원한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = cv2.imread('./image.jpg')\n",
    "_, binary = cv2.threshold(src, 127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "cv2.imshow('binary', binary)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "원본 이미지에 직접적으로 이진화 함수를 적용한 예제. 색상이 극단적으로 표현되는 것을 알 수 있다. 채널마다 임곗값을 적용해서 반환하므로,  각 채널은 두 종류의 값으로 나뉜다. 결국 다중 채널 이미지에 이진화가 적용된 채널들이 다시 병합되어 하나의 이미지로 변해서 활용하기 어려운 이미지가 된다. 이러한 문제로 특별한 경우가 아닌 이상 다중 채널 이미지에는 이진화 함수를 적용하지 않는다."
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIQAAAASCAYAAACae3b5AAACeklEQVRoBe1Yi5HrMAhUXRREE++KoBqaoRhukH2WLOtrx7Ff4sxkRrIcYNGyInL6fJ4MRBlw0bg8FFGR8vJHrnwy5gq2JiGESNl2XEiRvoMVn4y5ha1JCBVWT4MvIsQ7MQujgnPqHCj6yjtZbxv72SaEj0+UaCbGyfHex/wbMAspYCg4AJqK7/QklLF1EYL5HdTdmwVRQpyOtdiEsCLtj3sMs8Uwvpm8ipsVs4R4Pb4atg0hhMknGAC8jP38QwVERfsWewhRApO9xjcLON5FVWFWZvGVYuO+rmVK2hLewPGW8yfUgzmOewchLMbojBAChQVAbNvG+/DtwRYIYfIFqMTsCXGguFI0nfO5EowBQj4OhEzlV6xZxSGhIvfQ6Li/EMo4IYwAyDT3D65ChuClH99+bDMhTK7i5JfkKwS3Hh1XCEbQpUCMEGTkXHtpzayy60oWLBzzx4otNXRxPoPfaZQQaO4l0rfSeS++I9gmQlinu+zGVKHva3BU1fwn8umieZqY7VzUn8ezMFjnHsvx5v0uf9Oxtflt9kGywdl3ooebI80Kqk6gbnw92Fr3EJN8hYCNYSuChKXC6JhCrP2brZEGrbAZ8xmdOzx6/Bmp+hWqEEMpW/64iBdThY7XCrYL+FrYOu8hrG8gZRFlk91YLeLYzhobq+FP7kkRwEt/VyuwJ6Yef76P6TVe2LTsz+fiWUhv6gY6pohZw9PDFrahe4ivu5+uJHaIEBU76ZL1C9ZfWIX//TOrHhepgVfMD95DvCKE/87GSYSwo8gt6nBNVobuIa4J8X5efWP6gbezrTuWcA9xvz15IrogAw8hLkj6nV0+hLjz7lwQ2y9y2kQCTUsWxgAAAABJRU5ErkJggg=="
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 오츠 알고리즘\n",
    "입력된 이미지의 밝기 분포(히스토그램)를 통해 최적의 임곗값을 찾아 이진화를 적용하는 알고리즘. 가능한 모든 임곗값을 고려해서 이미지 내의 픽셀들을 두 개의 클래스로 분류했을 때 클래스 간의 분산을 최소화하거나 차이를 최대화하는 임곗값을 찾는다.</p>\n",
    "- 오츠 알고리즘 수식: ![image.png](attachment:image.png)\n",
    "\n",
    "(수식을 최소화하는 임곗값을 찾는다.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
